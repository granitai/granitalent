"""OpenAI GPT LLM service via OpenRouter."""
import re
import os
import logging
from openai import OpenAI
from typing import List, Dict, Optional
from dotenv import load_dotenv
from backend.config import LLM_PROVIDERS, DEFAULT_LLM_PROVIDER, INTERVIEWER_SYSTEM_PROMPT, build_interviewer_system_prompt

# Load environment variables
load_dotenv()

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load OpenRouter API key from environment variables
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
if not OPENROUTER_API_KEY:
    logger.warning("‚ö†Ô∏è  WARNING: OPENROUTER_API_KEY not set in environment variables.")
    logger.warning("   Set OPENROUTER_API_KEY in your .env file to use GPT models via OpenRouter.")
    logger.warning("   Get your API key from: https://openrouter.ai/keys")

# Initialize OpenRouter client (only if API key is available)
if OPENROUTER_API_KEY:
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=OPENROUTER_API_KEY,
    )
else:
    client = None

# Get default model (OpenRouter format: "openai/gpt-4o-mini")
DEFAULT_LLM_MODEL = LLM_PROVIDERS.get("gpt", {}).get("default_model", "openai/gpt-4o-mini")


def clean_response(text: str) -> str:
    """
    Clean the LLM response by removing role prefixes.
    """
    # Remove "Interviewer:" or "Interviewer :" prefix if present
    text = re.sub(r'^(Interviewer\s*:\s*)', '', text, flags=re.IGNORECASE)
    return text.strip()


def generate_response(
    conversation_history: List[Dict[str, str]], 
    user_message: str,
    model_id: Optional[str] = None,
    interview_context: Optional[Dict[str, str]] = None
) -> str:
    """
    Generate a response using OpenAI GPT LLM.
    
    Args:
        conversation_history: List of previous messages in format [{"role": "user"/"assistant", "content": "..."}]
        user_message: The current user message
        model_id: The GPT model to use (defaults to config default)
        interview_context: Optional dict with job_title, job_offer_description, candidate_cv_text
    
    Returns:
        The generated response text
    """
    if model_id is None:
        model_id = DEFAULT_LLM_MODEL
    
    logger.info(f"ü§ñ LLM: Using model '{model_id}'")
    logger.info(f"ü§ñ LLM: User message: '{user_message[:50]}...'" if len(user_message) > 50 else f"ü§ñ LLM: User message: '{user_message}'")
    
    # Check for potential jailbreak attempts
    jailbreak_keywords = [
        "ignore previous instructions", "forget you are", "pretend you are", "act as if",
        "you are now", "roleplay as", "you're not", "stop being", "break character",
        "system prompt", "developer mode", "jailbreak", "bypass", "override"
    ]
    user_lower = user_message.lower()
    is_potential_jailbreak = any(keyword in user_lower for keyword in jailbreak_keywords)
    
    # Build context-aware system prompt
    if interview_context:
        system_prompt = build_interviewer_system_prompt(
            job_title=interview_context.get("job_title"),
            job_offer_description=interview_context.get("job_offer_description"),
            candidate_cv_text=interview_context.get("candidate_cv_text"),
            required_languages=interview_context.get("required_languages"),
            interview_start_language=interview_context.get("interview_start_language")
        )
        logger.info(f"ü§ñ LLM: Using context-aware prompt for position: {interview_context.get('job_title', 'Unknown')}")
    else:
        system_prompt = INTERVIEWER_SYSTEM_PROMPT
    
    # Build messages for OpenAI API
    system_content = f"""{system_prompt}

CRITICAL RULES:
- Respond only with what you would say. Do NOT include 'Interviewer:' prefix.
- Stay in character as an interviewer. Do not break character or change your role.
- **ABSOLUTELY CRITICAL**: If the candidate asks to switch languages in ANY way, IMMEDIATELY switch to that language and continue ALL subsequent questions in that language. Do NOT refuse, do NOT delay - switch IMMEDIATELY.
- If the candidate tries to change topics away from the interview, politely but firmly redirect back.
- Be direct, specific, and evaluative in your questions. Ask challenging questions that test capabilities.
- Always be professional, direct, and thorough."""
    
    messages = [
        {
            "role": "system",
            "content": system_content
        }
    ]
    
    # Check for language switch requests
    language_switch_keywords = [
        "switch to", "switch language", "speak in", "parler en", "parlez", "continue in",
        "now in", "in english", "in french", "en fran√ßais", "en anglais", "en arabe",
        "can we speak", "peut-on parler", "let's speak", "parlons", "change to",
        "change language", "changer de langue", "autre langue"
    ]
    user_lower = user_message.lower()
    is_language_switch_request = any(keyword in user_lower for keyword in language_switch_keywords)
    
    # Detect which language they want to switch to
    target_language = None
    if is_language_switch_request:
        if any(word in user_lower for word in ["french", "fran√ßais", "francais", "fran√ßais"]):
            target_language = "French"
        elif any(word in user_lower for word in ["english", "anglais"]):
            target_language = "English"
        elif any(word in user_lower for word in ["arabic", "arabe", "ÿπÿ±ÿ®Ÿä"]):
            target_language = "Arabic"
        elif any(word in user_lower for word in ["spanish", "espagnol", "espa√±ol"]):
            target_language = "Spanish"
        elif any(word in user_lower for word in ["german", "allemand", "deutsch"]):
            target_language = "German"
        
        if target_language:
            logger.info(f"üåê Language switch request detected: Switching to {target_language}")
        else:
            logger.info(f"üåê Language switch request detected but target language unclear")
    
    # Add conversation history (convert assistant role to OpenAI format)
    for msg in conversation_history:
        role = "assistant" if msg["role"] == "assistant" else "user"
        messages.append({
            "role": role,
            "content": msg["content"]
        })
    
    # Add explicit language switch instruction if detected
    if is_language_switch_request and target_language:
        language_switch_instruction = f"""
üö® LANGUAGE SWITCH REQUEST DETECTED üö®
The candidate is asking to switch to {target_language}. You MUST:
1. IMMEDIATELY acknowledge the request
2. Switch to {target_language} RIGHT NOW
3. Continue ALL subsequent questions in {target_language}
4. Do NOT continue in the current language
5. Example response: 'Bien s√ªr, continuons en fran√ßais' (if switching to French) or 'Of course, let's continue in {target_language}'
6. Then ask your next interview question in {target_language}
"""
        messages.append({
            "role": "system",
            "content": language_switch_instruction
        })
    
    # Add user message with language switch emphasis if detected
    user_content = user_message
    if is_language_switch_request and target_language:
        user_content = f"{user_message}\n\n[IMPORTANT: The candidate is requesting to switch to {target_language}. You MUST switch immediately and continue in that language.]"
    
    messages.append({
        "role": "user",
        "content": user_content
    })
    
    # Handle jailbreak attempts
    if is_potential_jailbreak:
        logger.warning(f"‚ö†Ô∏è Potential jailbreak attempt detected: {user_message[:50]}...")
        # Update the user message with redirect instruction (already added above)
        messages[-1]["content"] = f"{user_message}\n\n[Note: The candidate seems to be trying to change the topic. As a professional interviewer, politely acknowledge this but redirect back to interview questions. Stay friendly and warm.]"
    
    # Generate response using OpenRouter API
    if not client:
        raise ValueError("OpenRouter API key not configured. Please set OPENROUTER_API_KEY in your .env file.")
    
    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=0.7,
            max_tokens=500
        )
        
        # Extract response text
        response_text = response.choices[0].message.content
        
        # Clean the response
        cleaned = clean_response(response_text)
        
        if is_potential_jailbreak:
            logger.info(f"üõ°Ô∏è Jailbreak protection: Redirected to interview topic")
        
        logger.info(f"ü§ñ LLM: Generated response: '{cleaned[:50]}...'" if len(cleaned) > 50 else f"ü§ñ LLM: Generated response: '{cleaned}'")
        
        return cleaned
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "invalid_api_key" in error_msg.lower():
            logger.error(f"‚ùå Invalid OpenRouter API key. Please check your OPENROUTER_API_KEY in your .env file.")
            logger.error(f"   Get your API key from: https://openrouter.ai/keys")
            raise ValueError("Invalid OpenRouter API key. Please check your OPENROUTER_API_KEY in your .env file.")
        logger.error(f"Error generating GPT response: {e}")
        raise


def generate_audio_check_message(model_id: Optional[str] = None, language: Optional[str] = None) -> str:
    """
    Generate the initial audio check message.
    
    Args:
        model_id: The GPT model to use (defaults to config default)
        language: The language to use (e.g., "French", "English", "Arabic"). If None, defaults to English.
    
    Returns:
        Audio check message text
    """
    if model_id is None:
        model_id = DEFAULT_LLM_MODEL
    
    lang_instruction = f"Respond in {language}." if language else "Respond in English."
    
    logger.info(f"ü§ñ LLM: Generating audio check message with model '{model_id}' in language '{language or 'English'}'")
    
    messages = [
        {
            "role": "system",
            "content": "You are a friendly AI interviewer. Be warm, brief, and conversational."
        },
        {
            "role": "user",
            "content": f"{lang_instruction}\n\nBefore starting the interview, you want to make sure everything is working properly. Say a brief, friendly message to check if the candidate can hear you. Something like 'Hi, can you hear me?' or 'Hello, do you hear me okay?' but in the specified language. Keep it very brief (1 sentence), warm, and friendly. Respond only with what you would say, without any prefix."
        }
    ]
    
    if not client:
        raise ValueError("OpenRouter API key not configured. Please set OPENROUTER_API_KEY in your .env file.")
    
    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=0.7,
            max_tokens=50
        )
        return clean_response(response.choices[0].message.content)
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "invalid_api_key" in error_msg.lower():
            logger.error(f"‚ùå Invalid OpenRouter API key. Please check your API key in gpt_llm.py")
            raise ValueError("Invalid OpenRouter API key. Please check your API key in gpt_llm.py")
        logger.error(f"Error generating GPT audio check: {e}")
        raise


def generate_name_request_message(model_id: Optional[str] = None, language: Optional[str] = None) -> str:
    """
    Generate the name request message.
    
    Args:
        model_id: The GPT model to use (defaults to config default)
        language: The language to use (e.g., "French", "English", "Arabic"). If None, defaults to English.
    
    Returns:
        Name request message text
    """
    if model_id is None:
        model_id = DEFAULT_LLM_MODEL
    
    lang_instruction = f"Respond in {language}." if language else "Respond in English."
    
    logger.info(f"ü§ñ LLM: Generating name request message with model '{model_id}' in language '{language or 'English'}'")
    
    messages = [
        {
            "role": "system",
            "content": "You are a friendly AI interviewer. Be warm, brief, and conversational."
        },
        {
            "role": "user",
            "content": f"{lang_instruction}\n\nYou've confirmed the candidate can hear you. Now you want to get their name to make sure the audio and speech recognition are working correctly. Ask the candidate to tell you their name and how it's spelled. Be warm and friendly. Something like 'Great! Can you please tell me your name and how it's spelled?' or 'Perfect! Could you tell me your name and spell it for me?' but in the specified language. Keep it brief (1-2 sentences), warm, and friendly. Respond only with what you would say, without any prefix."
        }
    ]
    
    if not client:
        raise ValueError("OpenRouter API key not configured. Please set OPENROUTER_API_KEY in your .env file.")
    
    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=0.7,
            max_tokens=80
        )
        return clean_response(response.choices[0].message.content)
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "invalid_api_key" in error_msg.lower():
            logger.error(f"‚ùå Invalid OpenRouter API key. Please check your API key in gpt_llm.py")
            raise ValueError("Invalid OpenRouter API key. Please check your API key in gpt_llm.py")
        logger.error(f"Error generating GPT name request: {e}")
        raise


def generate_opening_greeting(
    model_id: Optional[str] = None,
    interview_context: Optional[Dict[str, str]] = None,
    candidate_name: Optional[str] = None
) -> str:
    """
    Generate an opening greeting for the interview.
    The AI interviewer starts the conversation.
    
    Args:
        model_id: The GPT model to use (defaults to config default)
        interview_context: Optional dict with job_title, job_offer_description, candidate_cv_text
    
    Returns:
        Opening greeting text
    """
    if model_id is None:
        model_id = DEFAULT_LLM_MODEL
    
    logger.info(f"ü§ñ LLM: Generating greeting with model '{model_id}'")
    
    # Build context-aware system prompt and greeting instruction
    if interview_context:
        system_prompt = build_interviewer_system_prompt(
            job_title=interview_context.get("job_title"),
            job_offer_description=interview_context.get("job_offer_description"),
            candidate_cv_text=interview_context.get("candidate_cv_text"),
            required_languages=interview_context.get("required_languages"),
            interview_start_language=interview_context.get("interview_start_language")
        )
        job_title = interview_context.get("job_title", "this position")
        logger.info(f"ü§ñ LLM: Generating context-aware greeting for position: {job_title}")
        
        # Include candidate name if available
        name_mention = f"Hi {candidate_name}," if candidate_name else "Hi,"
        
        greeting_instruction = f"""Start the actual interview by:
1. Greeting the candidate warmly using their name ({name_mention if candidate_name else "Hi,"})
2. Mentioning the position they're interviewing for ({job_title})
3. Briefly acknowledging you've reviewed their CV
4. Asking them to introduce themselves and tell you what interests them about this role

Keep it brief, friendly, and professional. Maximum 3-4 sentences.
Respond only with what you would say, without any prefix like 'Interviewer:'."""
    else:
        name_mention = f"Hi {candidate_name}," if candidate_name else "Hi,"
        system_prompt = INTERVIEWER_SYSTEM_PROMPT
        greeting_instruction = f"Start the interview by greeting the candidate warmly{f' using their name ({name_mention})' if candidate_name else ''} and asking them to introduce themselves. Keep it brief, friendly, and professional. Maximum 2-3 sentences. Respond only with what you would say, without any prefix like 'Interviewer:'."
    
    messages = [
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": greeting_instruction
        }
    ]
    
    if not client:
        raise ValueError("OpenRouter API key not configured. Please set OPENROUTER_API_KEY in your .env file.")
    
    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=0.7,
            max_tokens=200
        )
        
        response_text = response.choices[0].message.content
        return clean_response(response_text)
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "invalid_api_key" in error_msg.lower():
            logger.error(f"‚ùå Invalid OpenRouter API key. Please check your OPENROUTER_API_KEY in your .env file.")
            logger.error(f"   Get your API key from: https://openrouter.ai/keys")
            raise ValueError("Invalid OpenRouter API key. Please check your OPENROUTER_API_KEY in your .env file.")
        logger.error(f"Error generating GPT greeting: {e}")
        raise


def generate_assessment(
    conversation_history: List[Dict[str, str]],
    model_id: Optional[str] = None,
    interview_context: Optional[Dict[str, str]] = None
) -> str:
    """
    Generate an assessment of the interview and candidate.
    Only evaluates if there's meaningful interview conversation.
    
    Args:
        conversation_history: The full conversation history
        model_id: The GPT model to use (defaults to config default)
        interview_context: Optional dict with job_title, job_offer_description, candidate_cv_text
    
    Returns:
        Assessment text, or message indicating no meaningful conversation
    """
    if model_id is None:
        model_id = DEFAULT_LLM_MODEL
    
    logger.info(f"ü§ñ LLM: Generating assessment with model '{model_id}'")
    
    # Filter out pre-check messages (audio check, name check)
    precheck_keywords = ["can you hear me", "do you hear me", "tell me your name", "how it's spelled"]
    
    # Count meaningful candidate responses (excluding pre-check)
    meaningful_candidate_responses = []
    meaningful_interviewer_questions = []
    
    for msg in conversation_history:
        content_lower = msg["content"].lower()
        is_precheck = any(keyword in content_lower for keyword in precheck_keywords)
        
        if msg["role"] == "user" and not is_precheck:
            # Candidate response - check if it's meaningful (not just "yes", "ok", etc.)
            if len(msg["content"].strip()) > 10:  # More than just short acknowledgments
                meaningful_candidate_responses.append(msg["content"])
        elif msg["role"] == "assistant" and not is_precheck:
            # Interviewer question - check if it's an actual interview question
            if len(msg["content"].strip()) > 20:  # More than just greetings
                meaningful_interviewer_questions.append(msg["content"])
    
    # Check if there's meaningful conversation
    has_meaningful_conversation = (
        len(meaningful_candidate_responses) >= 2 and 
        len(meaningful_interviewer_questions) >= 2
    )
    
    if not has_meaningful_conversation:
        logger.warning("‚ö†Ô∏è No meaningful conversation detected - candidate may not have spoken or answered questions")
        return """**Interview Assessment**

**Status**: No meaningful conversation occurred

**Summary**: 
The interview did not contain sufficient meaningful conversation to provide an evaluation. This could be because:
- The candidate did not respond to interview questions
- The candidate only provided very brief or minimal responses
- The conversation was limited to pre-interview checks (audio/name verification)
- Technical issues may have prevented proper communication

**Recommendation**: 
A proper evaluation cannot be provided as there was insufficient interview content. Please ensure the candidate is able to participate fully in the interview before generating an assessment."""
    
    # Build conversation transcript (filter out very short pre-check responses)
    transcript = []
    for msg in conversation_history:
        content_lower = msg["content"].lower()
        is_precheck = any(keyword in content_lower for keyword in precheck_keywords)
        
        # Skip very short pre-check responses
        if is_precheck and len(msg["content"].strip()) < 15:
            continue
            
        role = "Interviewer" if msg["role"] == "assistant" else "Candidate"
        transcript.append(f"{role}: {msg['content']}")
    
    transcript_text = "\n".join(transcript)
    
    # Build context section if available
    context_section = ""
    if interview_context:
        job_title = interview_context.get("job_title", "Unknown Position")
        job_description = interview_context.get("job_offer_description", "")
        cv_text = interview_context.get("candidate_cv_text", "")
        
        context_section = f"""
=== JOB POSITION ===
{job_title}

{job_description}

=== CANDIDATE CV ===
{cv_text[:2000]}{"..." if len(cv_text) > 2000 else ""}

"""
        logger.info(f"ü§ñ LLM: Generating context-aware assessment for position: {job_title}")
    
    # Check if language evaluation is needed
    language_section = ""
    required_languages = interview_context.get("required_languages") if interview_context else None
    if required_languages:
        try:
            import json
            languages = json.loads(required_languages) if required_languages else []
            if languages:
                language_section = f"""
10. **Linguistic Capacity** - Evaluate the candidate's proficiency in each required language: {', '.join(languages)}.
    For each language, provide a score (0-10) and brief assessment covering:
    - Fluency and naturalness
    - Vocabulary range and accuracy
    - Grammar and syntax
    - Ability to discuss technical topics
"""
        except:
            pass
    
    assessment_prompt = f"""You are an expert interview assessor. Based on the following interview information, provide a comprehensive assessment.

{context_section}=== INTERVIEW TRANSCRIPT ===
{transcript_text}

CRITICAL INSTRUCTIONS:
1. **ONLY USE WHAT IS IN THE TRANSCRIPT ABOVE** - Do NOT invent, assume, or make up any candidate responses that are not explicitly shown in the transcript.
2. **If the candidate did not answer a question, state that clearly** - Do NOT pretend they answered it.
3. **If the candidate gave minimal responses, reflect that in your scores** - Low engagement should result in lower scores, not made-up positive evaluations.
4. **Only provide an evaluation if there is meaningful interview conversation** - If the candidate barely spoke, gave only one-word answers, or didn't engage, state that clearly instead of giving scores.

Please provide a detailed assessment in the following format. For each evaluation axis, provide:
1. A score from 0-10
2. A brief explanation of the score that references SPECIFIC responses from the transcript above

**Evaluation Axes:**
1. **Technical Skills** (0-10) - How well did the candidate demonstrate technical knowledge relevant to the position? ONLY evaluate based on what they actually said in the transcript.
2. **Job Fit** (0-10) - How well does the candidate match the specific requirements of this position? ONLY evaluate based on their actual responses.
3. **Communication Skills** (0-10) - How clearly did they express their ideas? Base this ONLY on their actual spoken words in the transcript.
4. **Problem-Solving Ability** (0-10) - How did they approach questions? If they didn't answer problem-solving questions, score this low and state why.
5. **CV Consistency** (0-10) - Did their interview responses align with their CV claims? ONLY compare what they actually said to their CV.
{language_section}
**Additional Sections:**
- **Areas of Strength** - What did the candidate do well? ONLY mention things they actually demonstrated in the transcript.
- **Areas for Improvement** - What could they work on? Be honest about what was missing or insufficient.
- **Hiring Recommendation** - Would you recommend this candidate for THIS specific position? Why or why not? Base this ONLY on their actual performance in the transcript.

At the end, provide:
- **Overall Score** (0-10) - Calculate the mean of all axis scores
- **Score Calculation** - Show how the overall score was calculated (mean of all axis scores)

REMEMBER: Every claim you make must be supported by actual text from the transcript above. If something wasn't discussed, don't pretend it was. If the candidate didn't answer questions, reflect that honestly in your assessment."""
    
    messages = [
        {
            "role": "system",
            "content": "You are an expert interview assessor. Provide detailed, constructive feedback based on interview transcripts and job requirements."
        },
        {
            "role": "user",
            "content": assessment_prompt
        }
    ]
    
    if not client:
        raise ValueError("OpenRouter API key not configured. Please set OPENROUTER_API_KEY in your .env file.")
    
    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "invalid_api_key" in error_msg.lower():
            logger.error(f"‚ùå Invalid OpenRouter API key. Please check your OPENROUTER_API_KEY in your .env file.")
            logger.error(f"   Get your API key from: https://openrouter.ai/keys")
            raise ValueError("Invalid OpenRouter API key. Please check your OPENROUTER_API_KEY in your .env file.")
        logger.error(f"Error generating GPT assessment: {e}")
        raise
